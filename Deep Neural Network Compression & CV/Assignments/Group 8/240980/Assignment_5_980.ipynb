{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d7d55cb",
   "metadata": {},
   "source": [
    "\n",
    "# Assignment: Linear Regression, Logistic Regression, and K-Means (From Scratch)\n",
    "\n",
    "**Instructions**\n",
    "- You are NOT allowed to use `scikit-learn` for model implementation, scaling.\n",
    "- You may use it for implementation of clustering\n",
    "- You may use: `numpy`, `matplotlib`, and standard Python libraries only.\n",
    "- Every step (scaling, loss, gradients, optimization) must be implemented manually.\n",
    "- Clearly comment your code and explain your reasoning in Markdown cells."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ff7cd5",
   "metadata": {},
   "source": [
    "\n",
    "## Question 1: Linear Regression from Scratch (with Standardization and Regularization)\n",
    "\n",
    "You are given a dataset `(X, y)`.\n",
    "\n",
    "### Tasks\n",
    "1. Implement **StandardScaler manually**:\n",
    "   - Compute mean and standard deviation for each feature.\n",
    "   - Standardize the features.\n",
    "2. Implement **Linear Regression using Gradient Descent**.\n",
    "3. Add **L2 Regularization (Ridge Regression)**.\n",
    "4. Plot:\n",
    "   - Loss vs iterations\n",
    "   - True vs predicted values\n",
    "\n",
    "Do NOT use `sklearn`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecaf5e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48cf71cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Implement StandardScaler manually ,  first read about it, how it works and then implement it \n",
    "class StandardScalerManual:\n",
    "    def fit(self, X):\n",
    "        self.mean = np.mean(X)\n",
    "        self.std_dev = np.var(X)**0.5\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return (X-self.mean)/self.std_dev\n",
    "    \n",
    "    def fit_transform(self, X):\n",
    "        self.mean = np.mean(X)\n",
    "        self.std_dev = np.var(X)**0.5\n",
    "        return (X-self.mean)/self.std_dev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b360ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Implement Linear Regression from scratch, here you have to also construct the regulization term coefficient of which will be\n",
    "# denoted by l2_lambda\n",
    "# try to implement L1 regularization or atlease read about it and where it is used\n",
    "\n",
    "\n",
    "# In l1 regularization penalty is of the form lambda*sigma(abs(w_i))\n",
    "\n",
    "def gradient_mse_l1_reg_linear(X,y,w_1,w_0,l):\n",
    "    predictions = w_1*X+w_0\n",
    "    errors = y - predictions\n",
    "    del_w1 = -2*np.dot(errors,X) + l*1 if w_1>0 else -2*np.dot(errors,X) - l*1 if w_1<0 else -2*np.dot(errors,X)\n",
    "    del_w0 = -2*np.sum(errors) + l*1 if w_0>0 else -2*np.sum(errors) - l*1 if w_0<0 else -2*np.sum(errors)\n",
    "    return (del_w1,del_w0)\n",
    "\n",
    "\n",
    "class LinearRegressionManual:\n",
    "    def __init__(self, lr=0.01, epochs=1000, l2_lambda=0.0):\n",
    "        self.lr = lr #learning rate\n",
    "        self.epochs = epochs\n",
    "        self.l2_lambda = l2_lambda\n",
    "        self.w_1 = 0\n",
    "        self.w_0 = 0\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        for i in range(self.epochs):\n",
    "            del_w1,del_w0 = gradient_mse_l1_reg_linear(X,y,self.w_1,self.w_0,self.l2_lambda)\n",
    "            self.w_1 -= self.lr*del_w1\n",
    "            self.w_0 -= self.lr*del_w0\n",
    "\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.w_1*X+self.w_0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5b8470",
   "metadata": {},
   "source": [
    "\n",
    "## Question 2: Logistic Regression from Scratch (with Standardization and Regularization)\n",
    "\n",
    "You are given a binary classification dataset.\n",
    "\n",
    "### Tasks\n",
    "1. Reuse your **manual StandardScaler**.\n",
    "2. Implement **Logistic Regression using Gradient Descent**.\n",
    "3. Use:\n",
    "   - Sigmoid function\n",
    "   - Binary Cross Entropy loss\n",
    "4. Add **L2 Regularization**.\n",
    "5. Report:\n",
    "   - Training loss curve\n",
    "   - Final accuracy\n",
    "\n",
    "Do NOT use `sklearn`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b6002a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Implement sigmoid function as told in the lectures\n",
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f344717c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Implement Logistic Regression from scratch and here also add the regularizaation term\n",
    "\n",
    "# only predictions form change in logistic regression otherwise all remains same\n",
    "\n",
    "def gradient_mse_l1_reg_logistic(X,y,w_1,w_0,l):\n",
    "    predictions = sigmoid(w_1*X+w_0)\n",
    "    errors = y - predictions\n",
    "    del_w1 = -2*np.dot(errors,X) + l*1 if w_1>0 else -2*np.dot(errors,X) - l*1 if w_1<0 else -2*np.dot(errors,X)\n",
    "    del_w0 = -2*np.sum(errors) + l*1 if w_0>0 else -2*np.sum(errors) - l*1 if w_0<0 else -2*np.sum(errors)\n",
    "    return (del_w1,del_w0)\n",
    "\n",
    "\n",
    "\n",
    "class LogisticRegressionManual:\n",
    "    def __init__(self, lr=0.01, epochs=1000, l2_lambda=0.0):\n",
    "        self.lr = lr #learning rate\n",
    "        self.epochs = epochs\n",
    "        self.l2_lambda = l2_lambda\n",
    "        self.w_1 = 0\n",
    "        self.w_0 = 0\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        for i in range(self.epochs):\n",
    "            del_w1,del_w0 = gradient_mse_l1_reg_logistic(X,y,self.w_1,self.w_0,self.l2_lambda)\n",
    "            self.w_1 -= self.lr*del_w1\n",
    "            self.w_0 -= self.lr*del_w0\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return sigmoid(self.w_1*X+self.w_0)\n",
    "\n",
    "    def predict(self, X):\n",
    "        if sigmoid(self.w_1*X+self.w_0)>=0.5:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d398a9ee",
   "metadata": {},
   "source": [
    "\n",
    "## Question 3: K-Means Clustering from Scratch (Matrix Clustering)\n",
    "\n",
    "You are given a **random matrix** `M` of shape `(n, m)`.\n",
    "\n",
    "### Tasks\n",
    "Implement K-Means clustering **from scratch** such that:\n",
    "\n",
    "1. Input:\n",
    "   - A random matrix `M`\n",
    "   - Number of clusters `k`\n",
    "2. Output:\n",
    "   - `assignment_table`: a matrix of same shape as `M`, where each element stores the **cluster label**\n",
    "   - `cookbook`: a dictionary (hashmap) where:\n",
    "     - Key = cluster index\n",
    "     - Value = list of **positions (i, j)** belonging to that cluster\n",
    "   - `centroids`: array storing centroid values\n",
    "\n",
    "You must cluster **individual elements**, not rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1b3b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Implement K-Means for matrix elements\n",
    "#CAN USE SK-LEARN FOR THIS TASK AS THIS TASK WILL HELP US DIRECTLY IN OUR PROJECT !\n",
    "\n",
    "# assuming data-points in M labeled as 1 and non data-points as 0\n",
    "\n",
    "def kmeans_matrix(M, k, max_iters=100):\n",
    "    '''\n",
    "    Returns:\n",
    "    assignment_table: same shape as M, contains cluster labels\n",
    "    cookbook: dict -> cluster_id : list of (i, j) positions\n",
    "    centroids: numpy array of centroid values\n",
    "    '''\n",
    "\n",
    "\n",
    "    points = np.argwhere(M == 1)\n",
    "\n",
    "    if len(points) < k:\n",
    "        raise ValueError(\"Not enough data points for k clusters\")\n",
    "\n",
    "    centroids = points[np.random.choice(len(points), k, replace=False)].astype(float)\n",
    "\n",
    "    assignment = np.zeros(len(points), dtype=int)\n",
    "\n",
    "    for _ in range(max_iters):\n",
    "\n",
    "        for i, (x, y) in enumerate(points):\n",
    "            dists = np.sum((centroids - np.array([x, y]))**2, axis=1)\n",
    "            assignment[i] = np.argmin(dists)\n",
    "\n",
    "        new_centroids = np.zeros_like(centroids)\n",
    "\n",
    "        for cluster_id in range(k):\n",
    "            cluster_points = points[assignment == cluster_id]\n",
    "            if len(cluster_points) > 0:\n",
    "                new_centroids[cluster_id] = cluster_points.mean(axis=0)\n",
    "            else:\n",
    "                new_centroids[cluster_id] = points[np.random.randint(len(points))]\n",
    "\n",
    "        if np.allclose(centroids, new_centroids):\n",
    "            break\n",
    "\n",
    "        centroids = new_centroids\n",
    "\n",
    "    assignment_table = -np.ones_like(M, dtype=int)\n",
    "    cookbook = {i: [] for i in range(k)}\n",
    "\n",
    "    for idx, (x, y) in enumerate(points):\n",
    "        cluster = assignment[idx]\n",
    "        assignment_table[x, y] = cluster\n",
    "        cookbook[cluster].append((x, y))\n",
    "\n",
    "    return assignment_table, cookbook, centroids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acceca75",
   "metadata": {},
   "source": [
    "\n",
    "## Submission Guidelines\n",
    "- Submit the completed `.ipynb` file.\n",
    "- Clearly label all plots and outputs.\n",
    "- Code readability and correctness matter.\n",
    "- Partial credit will be given for logically correct implementations.\n",
    "\n",
    "**Bonus**\n",
    "- Compare convergence with and without standardization.\n",
    "- Try different values of regularization strength.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
