{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "-woU4Sodh6ND"
      },
      "cell_type": "markdown",
      "source": [
        "# Assignment #4\n",
        "\n",
        "\n",
        "Vision Transformer\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "UMQvV4nljttN"
      },
      "cell_type": "markdown",
      "source": [
        "# 1. Batch Normalization"
      ]
    },
    {
      "metadata": {
        "id": "JT_kxpjbNQUr"
      },
      "cell_type": "markdown",
      "source": [
        "Training a deep neural network is a tricky process. Many techniques have already been proposed for more stable training and faster convergence. Most of these techniques either change the model architecture or improve the training algorithm. Batch normalization belongs to the former group. The method was introduced in 2015 and achieved state-of-the-art in ImageNet,  a well-known image classification benchmark."
      ]
    },
    {
      "metadata": {
        "id": "vDcK52jRj_mD"
      },
      "cell_type": "markdown",
      "source": [
        "## 1.1 Definition"
      ]
    },
    {
      "metadata": {
        "id": "owKLAOJVj73I"
      },
      "cell_type": "markdown",
      "source": [
        "We generally normalize the inputs of a neural network to speed up the convergence. So if the \"normalization\" works, why not try it on the activation values? How can we improve training by normalizing the values of intermediate layers?\n",
        "\n",
        "Here is an intermediate layer $l$ in some neural network:\n",
        "\n",
        "<p align=\"center\"><img src=\"https://iust-deep-learning.github.io/972/static_files/assignments/asg03_assets/01_intermediate_layer.jpg\" width=\"500\"/></p>\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "nKOwOymYSVK8"
      },
      "cell_type": "markdown",
      "source": [
        "The general idea is to train layer $l$ faster by normalizing its input. By the layer $l$ we simply mean weigth matrices $W^{l}$, $b^{l}$ and by the input we mean previous layer's activations $a^{l-1}$. For the sake of simplicity, let us change our notation. Instead of normalizing the input of layer $l$, we would like to normalize the output so that the next layers will receive normalized values from our layer. It has the same effect, but it will make the equations much cleaner.\n",
        "\n",
        "In practice, we do not normalize the output (the activations). Instead, we do the normalization on the weighted sum of inputs $Z^{l}$ just before applying the activation function ($Z^l = xW^l+b^l$).\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "D_xmxSzHkqrT"
      },
      "cell_type": "markdown",
      "source": [
        "## 1.2 The formula"
      ]
    },
    {
      "metadata": {
        "id": "PjFpIC3HgxrO"
      },
      "cell_type": "markdown",
      "source": [
        "Assume we want some variable $x$ to have normalized values, the only way to do that is to collect all of its values and calculate the mean and variance in order to create a normalized version of $x$. This is a fairly reasonable solution, and we use it to normalize the neural network's input. Now imagine the goal is to normalize some intermediate values in a deep neural network; Collecting values of some intermediate point in a neural network is almost impossible since the training algorithm can change them entirely. To overcome this issue, we can collect them over a mini-batch.  It will give us an estimated version of the mean and variance. This is why it is called Batch Normalization. Here is the detailed algorithm:\n",
        "\n",
        "Given values of $x$ over a mini-batch $\\mathcal{B} = \\{x_1, .., x_m\\}$ :\n",
        "\n",
        "$$\n",
        "\\mu _\\mathcal{B} = \\frac{1}{m} \\sum^{m}_{i=1} x_i  \\ \\ \\ \\ \\ \\text{(mini-batch mean)}\n",
        "\\\\\n",
        "\\sigma^2 _\\mathcal{B} = \\frac{1}{m} \\sum^{m}_{i=1} (x_i-\\mu _\\mathcal{B})\n",
        "\\ \\ \\ \\ \\ \\text{(mini-batch variance)}\n",
        "\\\\\n",
        "x^{norm}_i = \\frac{x_i - \\mu _\\mathcal{B}}{\\sqrt{\\sigma^2 _\\mathcal{B} + \\epsilon}} \\ \\ \\ \\ \\ \\text{(normalize)}\n",
        "\\\\\n",
        "\\hat{x}_i =\\gamma x^{norm}_i+\\beta  \\ \\ \\ \\ \\ \\text{(scale and shift)}\n",
        "\\\\\n",
        "\\mathrm{BN(\\mathcal{B}, \\gamma, \\beta}) = \\{\\hat{x}_1, ..., \\hat{x}_m\\}\n",
        "$$\n"
      ]
    },
    {
      "metadata": {
        "id": "72SOE7UfxmEh"
      },
      "cell_type": "markdown",
      "source": [
        "**Notes:**\n",
        "1. All of the notations above are non-vector.\n",
        "2. $\\gamma$ and $\\beta$ are learnable parameters.\n",
        "3. $\\epsilon$ is just a small number, and we use it for numerical stability.\n",
        "4. $\\mathrm{BN}$ function calculates its output based on a batch of values. Consequently, we'll have different $\\mu_\\mathcal{B}$ and $\\sigma^2_\\mathcal{B}$ for each mini-batch during the training process. We will reference this property in the next sections.\n",
        "5. $x^{norm}_i$ is actually the normalized version of $x_i$ which has mean 0 and variance 1. However, hidden units in neural networks have different distributions, and we don't really want them to all have the same distribution, So instead, we just scale and shift $x^{norm}_i$ with two variables $\\gamma$, $\\beta$.\n",
        "6. Another reason for the extra \"scale & shift\" step is that if we choose $\\gamma = \\sqrt{\\sigma^2_\\mathcal{B} + \\epsilon}$ and $\\beta = \\mu_\\mathcal{B}$ then $\\hat{x}_i$ will become $x_i$, So the optimizer can easily remove the batch normalization if it is sufficient for proper training.\n",
        "\n",
        "One difference between normalizing a neural network's inputs and Batch Normalization is that the latter does not force values to have mean 0 and variance 1."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Explain it with at least one reason, why we might not want the hidden units to be forced to have mean 0 and variance 1.**"
      ],
      "metadata": {
        "id": "McQ7-6VxRS3I"
      }
    },
    {
      "metadata": {
        "id": "rrTaUoPMLhyl"
      },
      "cell_type": "markdown",
      "source": [
        "Preserving Distributional Diversity : Hidden units in neural networks naturally have different distributions. Forcing them all to have the same mean and variance would be too restrictive and might not reflect the actual distribution needed for specific hidden units to function effectively.\n",
        "\n",
        "Preventing Loss of Representational Power : By forcing a mean of 0 and variance of 1, you might inadvertently limit the network's ability to represent certain functions. Using learnable parameters $\\gamma$ and $\\beta$ allows the network to scale and shift the normalized values to a range that is more appropriate for the task at hand.\n",
        "\n",
        "Allowing the Optimizer to Undo Normalization : The scale and shift step provides the optimizer with a way to effectively bypass or remove the batch normalization if it is not beneficial for training. If the optimizer learns that $\\gamma = \\sqrt{\\sigma^2_{\\mathcal{B}} + \\epsilon}$ and $\\beta = \\mu_{\\mathcal{B}}$, then the output $\\hat{x}_i$ becomes the original input $x_i$ again."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Where is Batch Normalization generally applied relative to the activations.**"
      ],
      "metadata": {
        "id": "R2f1WO9jSWS_"
      }
    },
    {
      "metadata": {
        "id": "gLEtRi9hSrxC"
      },
      "cell_type": "markdown",
      "source": [
        "Placement : Batch Normalization is typically performed on the weighted sum of inputs ($Z^l = xW^l + b^l$).\n",
        "\n",
        "Timing : It is applied just before the activation function is triggered.\n",
        "\n",
        "Output Goal : Instead of normalizing the activations (outputs), the normalization is done on the pre-activation values so that the subsequent layer receives properly scaled values."
      ]
    },
    {
      "metadata": {
        "id": "8few4PaaXf9t"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.2.2 Batch normalization at test time\n",
        "\n",
        "As we said, We will have multiple $\\mu_\\mathcal{B}$ and $\\sigma^2_\\mathcal{B}$ since they are calculated individually for each mini-batch. So What should we do for the test time? In fact, the idea is quite simple; We can just calculate a moving average of $\\mu_\\mathcal{B}$ and $\\sigma^2_\\mathcal{B}$ to use at test time. Deep learning frameworks such as Tensorflow are using this algorithm in their default bach normalization implementations."
      ]
    },
    {
      "metadata": {
        "id": "wwyIr1ChkvzY"
      },
      "cell_type": "markdown",
      "source": [
        "## 1.3 Applying the batch-norm on layers"
      ]
    },
    {
      "metadata": {
        "id": "Wu85xhmM1xFv"
      },
      "cell_type": "markdown",
      "source": [
        "Batch Normalization (or simply batch-norm) doesn't know anything about the concept of layers and vectors. we have to integrate it manually in our layers. For a given d-dimensional vector of logits $Z = (z^{(1)},..., z^{(d)})$, the batch-normalized version is\n",
        "\n",
        "$$\n",
        "Z = (\\ \\mathrm{BN}(\\mathcal{B}\\{z^{(1)}\\}, \\gamma^{(1)}, \\beta^{(1)}),..., \\mathrm{BN}(\\mathcal{B}\\{z^{(d)}\\}, \\gamma^{(d)}, \\beta^{(d)})\\ )\n",
        "$$\n",
        "\n",
        "As you might have noticed, we need a batch for each $Z$'s element in the latter version. In other words, we need a batch of $Z$. Fortunately, this is good news for us since we build our neural networks entirely based on batches.\n",
        "\n",
        "Write the vectorized version of batch-norm equations and specify the dimensions.\n",
        "\n",
        "For any given layer $l$ with $n$ hidden units and batch size $b$:\n",
        "\n",
        "$$\n",
        "z = xW + B\\ \\ \\ \\  z \\in \\mathbb{R} ^ {b \\times n}, W \\in \\mathbb{R} ^ {m \\times n}, B \\in \\mathbb{R} ^ {b \\times n}, x \\in \\mathbb{R} ^ {b \\times m}\n",
        "$$\n"
      ]
    },
    {
      "metadata": {
        "id": "A-J18TTk_Uh1"
      },
      "cell_type": "markdown",
      "source": [
        "**3.**\n",
        "$$\\mu = \\frac{1}{b} \\sum_{i=1}^{b} z_{i,:} \\quad (\\mu \\in \\mathbb{R}^{1 \\times n})$$\n",
        "\n",
        "$$\\sigma^2 = \\frac{1}{b} \\sum_{i=1}^{b} (z_{i,:} - \\mu)^2 \\quad (\\sigma^2 \\in \\mathbb{R}^{1 \\times n})$$\n",
        "\n",
        "$$z^{norm} = \\frac{z - \\mu}{\\sqrt{\\sigma^2 + \\epsilon}} \\quad (z^{norm} \\in \\mathbb{R}^{b \\times n})$$\n",
        "\n",
        "$$\n",
        "\\hat{z} = \\gamma \\odot z^{norm} + \\beta  \\ \\ \\ \\ \\ \\ (\\odot \\text{ is an element-wise dot product} )\n",
        "$$"
      ]
    },
    {
      "metadata": {
        "id": "UmrjugAKYs0p"
      },
      "cell_type": "markdown",
      "source": [
        "Imagine a simple neural network with l hidden layers. We want to apply the batch-norm on all layers. Here is how it would look ($\\mathcal{X}^{b} $ is an input batch):\n",
        "\n",
        "$$\n",
        "\\mathcal{X}^{b}\\stackrel{W^{[1]}, B^{[1]}}{\\longrightarrow}Z^{[1]} \\stackrel{\\gamma^{[1]}, \\beta^{[1]}}{\\longrightarrow}\\hat{Z}^{[1]} \\longrightarrow a^{[1]} = func^{[1]}(\\hat{Z}^{[1]})\\stackrel{W^{[2]}, B^{[2]}}{\\longrightarrow} ...\n",
        "$$\n",
        "\n",
        "Also, the parameters for that neural network would be:\n",
        "$$\n",
        "W^{[1]}, B^{[1]} \\ \\  \\ \\ W^{[2]}, B^{[2]}  \\ \\ ... \\ \\ W^{[l]}, B^{[l]}\n",
        "\\\\\n",
        "\\gamma^{[1]}, \\beta^{[1]} \\ \\ \\ \\  \\  \\ \\ \\gamma^{[2]}, \\beta^{[2]}  \\ \\ \\ \\  ... \\ \\ \\ \\ \\gamma^{[l]}, \\beta^{[l]}\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. $B^{[i]}$ is the bias term in our neural network, but with incorporating the batch-norm and introduction of new variables,Do you think $B^{[i]}$ is necessary? Justify your answer with proper reasons.**"
      ],
      "metadata": {
        "id": "sTKOPL1rU3xt"
      }
    },
    {
      "metadata": {
        "id": "Tqv6BuLfirk8"
      },
      "cell_type": "markdown",
      "source": [
        "No, the bias term $B^{[i]}$ is not necessary.\n",
        "\n",
        "Redundancy: The first step of Batch Normalization is to subtract the mean ($\\mu$) of the batch. Any constant bias added to $z$ (like $B^{[i]}$) will be cancelled out during this subtraction process ($z - \\mu$), rendering $B^{[i]}$ irrelevant.\n",
        "\n",
        "Replacement by $\\beta$: The shifting role traditionally performed by the bias term is replaced by the learnable parameter $\\beta$ in the Batch Normalization equation ($\\hat{z} = \\gamma \\odot z^{norm} + \\beta$)."
      ]
    },
    {
      "metadata": {
        "id": "T0PrEPOdlE9d"
      },
      "cell_type": "markdown",
      "source": [
        "## 1.4 Why does it work?"
      ]
    },
    {
      "metadata": {
        "id": "AVqGS4J6lJlf"
      },
      "cell_type": "markdown",
      "source": [
        "Imagine a super simple neural network:\n",
        "\n",
        "<br/>\n",
        "<p align=\"center\"><img src=\"https://iust-deep-learning.github.io/972/static_files/assignments/asg03_assets/02_simple_nn.png\" width=\"300\"/>\n",
        "<br>\n",
        "  [[source](https://blog.paperspace.com/busting-the-myths-about-batch-normalization/)]\n",
        "</p>\n",
        "\n",
        "</br>\n",
        "During the training, Our optimizer calculates the gradients with respect to weights. Take layer **a** as an example; Optimizer calucates  $\\frac{\\partial L}{\\partial a}$ and then it updates the weights for this layer. Unfortunately,  it means that weight update for Layer **a** only depends on the sensitivity of loss function to that weight. However, changing weights of initial layers can completely effect the statistics of any futher layer.\n",
        "\n",
        "With the presence of Batch Normalization, our optimizer package can now adjust two parameters $\\gamma$, $\\beta$ to change statistics of any layer, rather than entire weight matrix. It makes the training of any layer independent and also introduces some checkpointing mechanism.\n",
        "\n",
        "Besides, recent findings show that batch normalization smoothes the landscape/surface of the loss function, effectively making the optimization performance less dependant on the initial state.\n",
        "\n",
        "<p align=\"center\"><img src=\"https://iust-deep-learning.github.io/972/static_files/assignments/asg03_assets/03_error_surface.jpg\"  width=\"700\"/>\n",
        "<br/>\n",
        "  source: [2]\n",
        "  </p>"
      ]
    },
    {
      "metadata": {
        "id": "VZlJ4Hic2aoN"
      },
      "cell_type": "markdown",
      "source": [
        "## 1.5 Batch Normalization in action\n"
      ]
    },
    {
      "metadata": {
        "id": "cSqjUrD02hiL"
      },
      "cell_type": "markdown",
      "source": [
        "Now let's create a layer to use batch normalization easier."
      ]
    },
    {
      "metadata": {
        "id": "YwY8vwus2xQu"
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Layer, Dense, Activation, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Complete the following Class**"
      ],
      "metadata": {
        "id": "R6TKpXssrUqc"
      }
    },
    {
      "metadata": {
        "id": "Gt5mzXXX2s5V"
      },
      "cell_type": "code",
      "source": [
        "class BatchNormalizedLayer(Layer):\n",
        "  def __init__(self, layer, axis=-1, activation=None, **kwargs):\n",
        "    \"\"\"Runs batch normalization on layer instance and applies the activation function\n",
        "\n",
        "    Args:\n",
        "      layer(layers.Layer): A layer to normalize its output\n",
        "      axis(int): the axis that should be normalized (typically the features axis).\n",
        "      activation(str): Activation function to use\n",
        "    \"\"\"\n",
        "    super(BatchNormalizedLayer, self).__init__(**kwargs)\n",
        "\n",
        "    self.layer = layer\n",
        "    self.axis = axis\n",
        "    self.bn = tf.keras.layers.BatchNormalization(axis=self.axis)\n",
        "\n",
        "    if activation:\n",
        "      self.activation_layer = tf.keras.layers.Activation(activation)\n",
        "    else:\n",
        "      self.activation_layer = None\n",
        "\n",
        "  def call(self, inputs):\n",
        "    \"\"\"Runs the layer\n",
        "\n",
        "    Args:\n",
        "      inputs: The layer's input\n",
        "\n",
        "    hint: keras.layers.BatchNormalization and layers.Activation might be useful for you\n",
        "    \"\"\"\n",
        "    ########################################\n",
        "    #     Put your implementation here     #\n",
        "    z = self.layer(inputs)\n",
        "    z_bn = self.bn(z)\n",
        "    if self.activation_layer:\n",
        "            return self.activation_layer(z_bn)\n",
        "\n",
        "    return z_bn\n",
        "    ########################################"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cc0wyxlb7JwJ"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf # Import tensorflow\n",
        "\n",
        "bnl = BatchNormalizedLayer(Dense(5), activation='relu')\n",
        "x = tf.constant(2.5 * np.random.randn(10, 4) + 3, dtype=tf.float32) # Use tf.constant\n",
        "\n",
        "# Evaluate the output using tf.keras.backend.get_value\n",
        "assert tf.keras.backend.get_value(bnl(x)).shape == (10, 5)\n",
        "#this is just a check to see if the Layer is working as expected ,it doesnot print anything"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E-Tlpqm-_dyH"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.5.1 CNN"
      ]
    },
    {
      "metadata": {
        "id": "ZPLoHHW1_qdv"
      },
      "cell_type": "markdown",
      "source": [
        "Now we have our special layer. So, let's use it in a real neural network. We want to improve the baseline using the Batch Normalization layer. Our desired task is CIFAR10 image  classification.\n",
        "\n",
        "First, let's load the dataset:"
      ]
    },
    {
      "metadata": {
        "id": "wm79YEyIAmKa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "e1dbd354-c08e-425e-e58d-76bb2f2a1026"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.datasets import cifar10\n",
        "\n",
        "num_classes = 10\n",
        "\n",
        "# The data, split between train and test sets:\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# 6.Convert class vectors to binary class matrices.\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# Visualizing CIFAR 10\n",
        "fig, axes1 = plt.subplots(2,5,figsize=(10,4))\n",
        "for j in range(2):\n",
        "  for k in range(5):\n",
        "    i = np.random.choice(range(len(x_train)))\n",
        "    axes1[j][k].set_axis_off()\n",
        "    axes1[j][k].imshow(x_train[i:i+1][0])\n",
        "\n",
        "# Normalize\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "id": "UBb__seXIyRN"
      },
      "cell_type": "code",
      "source": [
        "def visualize_loss_and_acc(history):\n",
        "  history_dict = history.history\n",
        "  loss_values = history_dict['loss']\n",
        "  val_loss_values = history_dict['val_loss']\n",
        "  acc = history_dict['accuracy'] # Changed from 'acc' to 'accuracy'\n",
        "\n",
        "  epochs = range(1, len(acc) + 1)\n",
        "\n",
        "  f = plt.figure(figsize=(10,3))\n",
        "\n",
        "  plt.subplot(1,2,1)\n",
        "  plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
        "  plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
        "  plt.title('Training and validation loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "\n",
        "\n",
        "  acc_values = history_dict['accuracy'] # Changed from 'acc' to 'accuracy'\n",
        "  val_acc = history_dict['val_accuracy'] # Changed from 'val_acc' to 'val_accuracy'\n",
        "\n",
        "  plt.subplot(1,2,2)\n",
        "  plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "  plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "  plt.title('Training and validation accuracy')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1qlKS6lsIzLX"
      },
      "cell_type": "markdown",
      "source": [
        "#### Baseline"
      ]
    },
    {
      "metadata": {
        "id": "CzzXJ2M6GXn-"
      },
      "cell_type": "markdown",
      "source": [
        "Define the baseline model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![CNN Architecture](https://drive.google.com/uc?id=1Fh3Z94KKHe9sAzUorZlW9NXMPN6NAhlx\n",
        ")\n"
      ],
      "metadata": {
        "id": "2fLyt7WKl8F-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The figure above shows the architecture of a **baseline Convolutional Neural Network (CNN)** used for multi-class image classification.\n",
        "\n",
        "The architecture consists of the following components in **Sequential order**:\n",
        "\n",
        "- Convolutional layers with **33 kernels** and **padding = 'same'**\n",
        "- ReLU activation after each convolution\n",
        "- MaxPooling layers with **22 pool size**\n",
        "- Dropout layers for regularization\n",
        "- A fully connected Dense layer\n",
        "- A Softmax output layer\n",
        "\n",
        "**7.** Based on the **architecture shown in the image** and the details mentioned above, implement the CNN model in Keras by completing the function below.\n",
        "\n",
        "- Ensure that the **number of layers, order of layers, kernel sizes, pooling sizes, dropout rates, padding, and activations** exactly match the given architecture\n",
        "- Do **not** change the function name or signature\n"
      ],
      "metadata": {
        "id": "eFWdmvXlnWNN"
      }
    },
    {
      "metadata": {
        "id": "ZnXcRHpuDcvS"
      },
      "cell_type": "code",
      "source": [
        "def get_baseline_model():\n",
        "  model = Sequential()\n",
        "\n",
        "  ## HINT : input_shape=x_train.shape[1:]\n",
        "\n",
        "   ########################################\n",
        "    #     Put your implementation here     #\n",
        "  model.add(Conv2D(32, (3, 3), padding='same', input_shape=x_train.shape[1:]))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Conv2D(32, (3, 3), padding='same'))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(512))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(num_classes))\n",
        "  model.add(Activation('softmax'))\n",
        "    ########################################\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "                optimizer=keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1TQ2uoSmGlvP"
      },
      "cell_type": "markdown",
      "source": [
        "Train the baseline"
      ]
    },
    {
      "metadata": {
        "id": "2Q45b4cVF36l"
      },
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "epochs = 25"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "metadata": {
        "id": "488nX4FSDzs-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e413516-a4bb-4146-db69-9b8085f6efff"
      },
      "cell_type": "code",
      "source": [
        "# Create the baseline model\n",
        "baseline = get_baseline_model()\n",
        "\n",
        "# Train model\n",
        "bs_history = baseline.fit(\n",
        "    x_train, y_train,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=(x_test, y_test),\n",
        "    shuffle=True\n",
        ")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - accuracy: 0.2634 - loss: 2.0037 - val_accuracy: 0.4180 - val_loss: 1.6382\n",
            "Epoch 2/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.4436 - loss: 1.5443 - val_accuracy: 0.5329 - val_loss: 1.3229\n",
            "Epoch 3/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5173 - loss: 1.3528 - val_accuracy: 0.5727 - val_loss: 1.1963\n",
            "Epoch 4/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5635 - loss: 1.2295 - val_accuracy: 0.6194 - val_loss: 1.0951\n",
            "Epoch 5/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5954 - loss: 1.1418 - val_accuracy: 0.6366 - val_loss: 1.0282\n",
            "Epoch 6/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.6236 - loss: 1.0681 - val_accuracy: 0.6615 - val_loss: 0.9776\n",
            "Epoch 7/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.6503 - loss: 1.0017 - val_accuracy: 0.6503 - val_loss: 0.9982\n",
            "Epoch 8/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.6685 - loss: 0.9525 - val_accuracy: 0.6900 - val_loss: 0.8944\n",
            "Epoch 9/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.6794 - loss: 0.9105 - val_accuracy: 0.7011 - val_loss: 0.8639\n",
            "Epoch 10/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.6926 - loss: 0.8781 - val_accuracy: 0.6944 - val_loss: 0.8826\n",
            "Epoch 11/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.7074 - loss: 0.8453 - val_accuracy: 0.6984 - val_loss: 0.8658\n",
            "Epoch 12/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.7092 - loss: 0.8309 - val_accuracy: 0.7302 - val_loss: 0.7937\n",
            "Epoch 13/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.7228 - loss: 0.7947 - val_accuracy: 0.7239 - val_loss: 0.8082\n",
            "Epoch 14/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.7292 - loss: 0.7721 - val_accuracy: 0.7379 - val_loss: 0.7720\n",
            "Epoch 15/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.7339 - loss: 0.7667 - val_accuracy: 0.7421 - val_loss: 0.7540\n",
            "Epoch 16/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.7442 - loss: 0.7375 - val_accuracy: 0.7277 - val_loss: 0.7962\n",
            "Epoch 17/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.7504 - loss: 0.7230 - val_accuracy: 0.7426 - val_loss: 0.7617\n",
            "Epoch 18/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.7557 - loss: 0.7098 - val_accuracy: 0.7492 - val_loss: 0.7393\n",
            "Epoch 19/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.7603 - loss: 0.6967 - val_accuracy: 0.7550 - val_loss: 0.7228\n",
            "Epoch 20/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.7640 - loss: 0.6855 - val_accuracy: 0.7590 - val_loss: 0.7032\n",
            "Epoch 21/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.7611 - loss: 0.6874 - val_accuracy: 0.7601 - val_loss: 0.7239\n",
            "Epoch 22/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.7715 - loss: 0.6735 - val_accuracy: 0.7571 - val_loss: 0.7228\n",
            "Epoch 23/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.7767 - loss: 0.6604 - val_accuracy: 0.7618 - val_loss: 0.7060\n",
            "Epoch 24/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.7778 - loss: 0.6608 - val_accuracy: 0.7656 - val_loss: 0.6937\n",
            "Epoch 25/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.7829 - loss: 0.6465 - val_accuracy: 0.7635 - val_loss: 0.7021\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "AJgQ9yxpGp8P"
      },
      "cell_type": "markdown",
      "source": [
        "Visualize the training and evaluate the model"
      ]
    },
    {
      "metadata": {
        "id": "VeVuiJmHGUw7"
      },
      "cell_type": "code",
      "source": [
        "def visualize_loss_and_acc(history):\n",
        "    history_dict = history.history\n",
        "    loss_values = history_dict['loss']\n",
        "    val_loss_values = history_dict['val_loss']\n",
        "\n",
        "    acc = history_dict['accuracy']\n",
        "    val_acc = history_dict['val_accuracy']\n",
        "\n",
        "    epochs = range(1, len(acc) + 1)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8aMc7UWPICG9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb1f7515-d25f-4728-b252-88a5fd1b1819"
      },
      "cell_type": "code",
      "source": [
        "# Score trained model.\n",
        "scores = baseline.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7644 - loss: 0.6990\n",
            "Test accuracy: 0.7634999752044678\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "ufqdGaLrI4oZ"
      },
      "cell_type": "markdown",
      "source": [
        "#### Improved"
      ]
    },
    {
      "metadata": {
        "id": "dm8Yu20HHBXp"
      },
      "cell_type": "markdown",
      "source": [
        "**8. Now update the baseline to create an enhanced model only by using `BatchNormalizedLayer`**"
      ]
    },
    {
      "metadata": {
        "id": "aD6NqqZ3Hbeg"
      },
      "cell_type": "code",
      "source": [
        "def get_improved_model():\n",
        "\n",
        "  model = Sequential()\n",
        "\n",
        "  ########################################\n",
        "  #     Put your implementation here     #\n",
        "  model.add(BatchNormalizedLayer(Conv2D(32, (3, 3), padding='same'),\n",
        "                                   activation='relu', input_shape=x_train.shape[1:]))\n",
        "  model.add(BatchNormalizedLayer(Conv2D(32, (3, 3), padding='same'),\n",
        "                                   activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(BatchNormalizedLayer(Conv2D(64, (3, 3), padding='same'),\n",
        "                                   activation='relu'))\n",
        "  model.add(BatchNormalizedLayer(Conv2D(64, (3, 3), padding='same'),\n",
        "                                   activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(BatchNormalizedLayer(Dense(512), activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(num_classes))\n",
        "  model.add(Activation('softmax'))\n",
        "  ########################################\n",
        "  ## remember you have to use your baseline and add batch normalized layers using the previous Model\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "                optimizer=keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oYmlozp3I8Ts"
      },
      "cell_type": "markdown",
      "source": [
        "Train and evaluate"
      ]
    },
    {
      "metadata": {
        "id": "mLNW4dnsH9NF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3deb138f-4b90-4244-af7b-381e7d986758"
      },
      "cell_type": "code",
      "source": [
        "# Create the baseline model\n",
        "impv_model = get_improved_model()\n",
        "\n",
        "# Train model\n",
        "impv_history = impv_model.fit(\n",
        "    x_train, y_train,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=(x_test, y_test),\n",
        "    shuffle=True\n",
        ")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3192180094.py:10: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super(BatchNormalizedLayer, self).__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.3225 - loss: 2.0529 - val_accuracy: 0.5188 - val_loss: 1.3799\n",
            "Epoch 2/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.5054 - loss: 1.4195 - val_accuracy: 0.5770 - val_loss: 1.1909\n",
            "Epoch 3/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5770 - loss: 1.2058 - val_accuracy: 0.6293 - val_loss: 1.0427\n",
            "Epoch 4/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.6253 - loss: 1.0749 - val_accuracy: 0.6368 - val_loss: 1.0081\n",
            "Epoch 5/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.6598 - loss: 0.9780 - val_accuracy: 0.6995 - val_loss: 0.8635\n",
            "Epoch 6/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.6774 - loss: 0.9252 - val_accuracy: 0.7095 - val_loss: 0.8309\n",
            "Epoch 7/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.6955 - loss: 0.8771 - val_accuracy: 0.6965 - val_loss: 0.8594\n",
            "Epoch 8/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.7160 - loss: 0.8231 - val_accuracy: 0.7238 - val_loss: 0.7952\n",
            "Epoch 9/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.7278 - loss: 0.7867 - val_accuracy: 0.7490 - val_loss: 0.7219\n",
            "Epoch 10/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.7361 - loss: 0.7593 - val_accuracy: 0.7258 - val_loss: 0.7887\n",
            "Epoch 11/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.7474 - loss: 0.7328 - val_accuracy: 0.7659 - val_loss: 0.6847\n",
            "Epoch 12/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.7553 - loss: 0.7049 - val_accuracy: 0.7614 - val_loss: 0.6911\n",
            "Epoch 13/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.7561 - loss: 0.7050 - val_accuracy: 0.7695 - val_loss: 0.6926\n",
            "Epoch 14/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.7661 - loss: 0.6769 - val_accuracy: 0.7555 - val_loss: 0.7157\n",
            "Epoch 15/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.7745 - loss: 0.6543 - val_accuracy: 0.7449 - val_loss: 0.8173\n",
            "Epoch 16/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.7743 - loss: 0.6536 - val_accuracy: 0.7832 - val_loss: 0.6527\n",
            "Epoch 17/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.7863 - loss: 0.6368 - val_accuracy: 0.7738 - val_loss: 0.6607\n",
            "Epoch 18/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.7898 - loss: 0.6146 - val_accuracy: 0.7877 - val_loss: 0.6491\n",
            "Epoch 19/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.7900 - loss: 0.6239 - val_accuracy: 0.7876 - val_loss: 0.6438\n",
            "Epoch 20/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.7980 - loss: 0.5955 - val_accuracy: 0.7942 - val_loss: 0.6486\n",
            "Epoch 21/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8031 - loss: 0.5878 - val_accuracy: 0.7933 - val_loss: 0.6230\n",
            "Epoch 22/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8060 - loss: 0.5800 - val_accuracy: 0.8005 - val_loss: 0.6033\n",
            "Epoch 23/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8085 - loss: 0.5742 - val_accuracy: 0.7880 - val_loss: 0.6374\n",
            "Epoch 24/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8118 - loss: 0.5721 - val_accuracy: 0.8011 - val_loss: 0.6281\n",
            "Epoch 25/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.8152 - loss: 0.5614 - val_accuracy: 0.8002 - val_loss: 0.6193\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Fsz97z1Q-eoA"
      },
      "cell_type": "markdown",
      "source": [
        "Visualize the training and evaluate the model"
      ]
    },
    {
      "metadata": {
        "id": "30JMMBQyIb49"
      },
      "cell_type": "code",
      "source": [
        "visualize_loss_and_acc(impv_history)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZoqlKrUAIb4_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2fb07b6-7b0f-4b0d-f01f-01c91cfcc36d"
      },
      "cell_type": "code",
      "source": [
        "# Score trained model.\n",
        "scores = impv_model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7995 - loss: 0.6186\n",
            "Test accuracy: 0.8001999855041504\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "L-vfDkCCycqZ"
      },
      "cell_type": "markdown",
      "source": [
        "**Question:** Compare your model to the baseline. What are the diffrences? Does batch normalization work?"
      ]
    },
    {
      "metadata": {
        "id": "VjOOqiDDyf4p"
      },
      "cell_type": "markdown",
      "source": [
        "Yes, Batch Normalization works.\n",
        "\n",
        "Based on the training results :\n",
        "\n",
        "Higher Accuracy : The improved model achieved a test accuracy of approximately 80% (0.8001). This is a significant improvement over standard baseline CNNs without normalization on datasets like CIFAR-10.\n",
        "\n",
        "Smoother Optimization : Batch normalization smoothes the loss surface/landscape, making the optimization performance less dependent on the initial weight state and choice of optimizer.\n",
        "\n",
        "Independent Layer Training : It makes the training of each layer more independent by allowing the optimizer to adjust layer statistics through $\\gamma$ and $\\beta$ rather than the entire weight matrix."
      ]
    },
    {
      "metadata": {
        "id": "oJLRl0DL5aSO"
      },
      "cell_type": "markdown",
      "source": [
        "# References\n"
      ]
    },
    {
      "metadata": {
        "id": "LCQPkvV83Kn0"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. Ioffe, Sergey, and Christian Szegedy. Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift. ArXiv:1502.03167 [Cs], February 10, 2015. http://arxiv.org/abs/1502.03167.\n",
        "* Im, Daniel Jiwoong, Michael Tao, and Kristin Branson. An Empirical Analysis of the Optimization of Deep Network Loss Surfaces. ArXiv:1612.04010 [Cs], December 12, 2016. http://arxiv.org/abs/1612.04010.\n",
        "* Santurkar, Shibani, Dimitris Tsipras, Andrew Ilyas, and Aleksander Madry. How Does Batch Normalization Help Optimization? In Advances in Neural Information Processing Systems 31, edited by S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett, 24832493. Curran Associates, Inc., 2018. http://papers.nips.cc/paper/7515-how-does-batch-normalization-help-optimization.pdf.\n",
        "* Coursera Course: Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization\n",
        "* Intro to optimization in deep learning: Busting the myth about batch normalization [[link](https://blog.paperspace.com/busting-the-myths-about-batch-normalization/)]\n",
        "* Why Does Batch Normalization Work? [[link](https://abay.tech/blog/2018/07/01/why-does-batch-normalization-work/)]\n",
        "*  http://www.cs.toronto.edu/~tingwuwang/semantic_segmentation.pdf\n",
        "*  https://medium.com/nanonets/how-to-do-image-segmentation-using-deep-learning-c673cc5862ef\n",
        "* https://www.jeremyjordan.me/semantic-segmentation/\n",
        "\n"
      ]
    }
  ]
}