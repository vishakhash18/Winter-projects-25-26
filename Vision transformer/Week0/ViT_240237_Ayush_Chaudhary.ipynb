{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ODQspt4QlJd"
   },
   "source": [
    "**SUBMISSION INSTRUCTIONS**\n",
    "\n",
    "It is recommendend that you make a copy of this colab file and then solve the assignment and upload your final notebook on github.\n",
    "\n",
    "Before uploading your downloaded notebook, **RENAME** the file as **rollno_name.ipynb**\n",
    "\n",
    "**Submission Deadline : 9/12/2025 Tuesday EOD i.e before 11:59 PM**\n",
    "\n",
    "The deadline is strict and will not be extended, Late submissions are not allowed\n",
    "\n",
    "Note that you have to upload your solution on the github page of the project Vision Transformer and under Week0\n",
    "\n",
    "**Github Submission repo** -\n",
    "https://github.com/electricalengineersiitk/Winter-projects-25-26/tree/main/Vision%20transformer/Week0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1979,
     "status": "ok",
     "timestamp": 1765211457700,
     "user": {
      "displayName": "Ayush Chaudhary",
      "userId": "00125398721957339855"
     },
     "user_tz": -330
    },
    "id": "cFWP80xqsF2d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZNfZsRArhgzY"
   },
   "source": [
    "#**Assignment 1**\n",
    "#**Section 1 (Python)**\n",
    "#**Problem 1**\n",
    "In this problem, you will implement a class that represents a data sample with numerical features.  \n",
    "##  Problem Statement\n",
    "Create a class named **`DataSample`** that stores:\n",
    "\n",
    "- A list of numeric **features**\n",
    "- A string **label**\n",
    "\n",
    "You must implement the following **three methods** with **exact names** (do NOT rename them):\n",
    "\n",
    "| Method | Description |\n",
    "|--------|------------|\n",
    "| `__init__(self, features, label)` | Initializes object attributes |\n",
    "| `min_max_norm(self)` | Apply min-max normalization **in-place** |\n",
    "| `scaled(self, factor)` | Return a **new list** with each feature multiplied by `factor` |\n",
    "\n",
    "### Min–Max Normalization Formula\n",
    "\n",
    "![Alt text for the image](https://miro.medium.com/v2/resize:fit:964/1*OnCBKS-Thqa43qNslohDpA.png)\n",
    "\n",
    "\n",
    "###  Edge Case\n",
    "If **all features are equal**, then max = min → division by zero.  \n",
    "Handle this condition by setting all normalized values to **0**.\n",
    "\n",
    "---\n",
    "\n",
    "### Your output must behave conceptually like this (not real execution here):\n",
    "```python\n",
    "sample = DataSample([10, 20, 30], \"cat\")\n",
    "sample.min_max_norm()\n",
    "print(sample.features)   # expected -> [0.0, 0.5, 1.0]\n",
    "\n",
    "print(sample.scaled(2))  # expected -> [0.0, 1.0, 2.0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZE60twaWkfVj"
   },
   "source": [
    "**Sample Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1765211457700,
     "user": {
      "displayName": "Ayush Chaudhary",
      "userId": "00125398721957339855"
     },
     "user_tz": -330
    },
    "id": "IuF2sGC1hfdT"
   },
   "outputs": [],
   "source": [
    "class DataSample:\n",
    "    def __init__(self, features, label):\n",
    "        \"\"\"\n",
    "        Initialize the object with feature list and label string.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def min_max_norm(self):\n",
    "        \"\"\"\n",
    "        Apply min-max normalization:\n",
    "        Modify self.features in-place.\n",
    "        Handle case where max == min.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def scaled(self, factor):\n",
    "        \"\"\"\n",
    "        Return a NEW list of features where each element is multiplied by factor.\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QwLsXPJVkr4e"
   },
   "source": [
    "You can check if your code is working correctly using the sample case below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "error",
     "timestamp": 1765211457701,
     "user": {
      "displayName": "Ayush Chaudhary",
      "userId": "00125398721957339855"
     },
     "user_tz": -330
    },
    "id": "wzoIfmumk0qO",
    "outputId": "0549bc1a-d451-4bfc-ce3a-4eb062d07a36"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataSample' object has no attribute 'features'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-3555955498.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"bird\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Original features:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Label:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataSample' object has no attribute 'features'"
     ]
    }
   ],
   "source": [
    "sample = DataSample([3.5, -2.0, 3.5, 10.0, 0.0], \"bird\")\n",
    "\n",
    "print(\"Original features:\", sample.features)\n",
    "print(\"Label:\", sample.label)\n",
    "\n",
    "sample.min_max_norm()\n",
    "print(\"After min-max normalization:\", sample.features)\n",
    "\n",
    "scaled_output = sample.scaled(4.2)\n",
    "print(\"After scaling x 4.2 (new list expected):\", scaled_output)\n",
    "\n",
    "# Expected Output:\n",
    "# Original features: [3.5, -2.0, 3.5, 10.0, 0.0]\n",
    "# Label: bird\n",
    "# After min-max normalization: [0.4583, 0.0, 0.4583, 1.0, 0.1667]  (approx values)\n",
    "# After scaling x 4.2: [1.659, 0.0, 1.659, 4.2, 0.84]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kv6aC1HrwJff"
   },
   "source": [
    "# **Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "aborted",
     "timestamp": 1765211457701,
     "user": {
      "displayName": "Ayush Chaudhary",
      "userId": "00125398721957339855"
     },
     "user_tz": -330
    },
    "id": "B6moI3Jiw15t"
   },
   "outputs": [],
   "source": [
    "class DataSample:\n",
    "    def __init__(self, features, label):\n",
    "        self.features = features\n",
    "        self.label = label\n",
    "\n",
    "    def min_max_norm(self):\n",
    "        if not self.features:\n",
    "            return\n",
    "\n",
    "        f_min = min(self.features)\n",
    "        f_max = max(self.features)\n",
    "\n",
    "        if f_max == f_min:\n",
    "            self.features = [0.0 for _ in self.features]\n",
    "        else:\n",
    "            range_val = f_max - f_min\n",
    "            self.features = [(x - f_min) / range_val for x in self.features]\n",
    "\n",
    "    def scaled(self, factor):\n",
    "        return [x * factor for x in self.features]\n",
    "\n",
    "sample = DataSample([10, 20, 30], \"cat\")\n",
    "sample.min_max_norm()\n",
    "print(sample.features)\n",
    "print(sample.scaled(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X1HdPuWooqWa"
   },
   "source": [
    "#**Problem 2**\n",
    "Sort Based on Unique Character Count\n",
    "\n",
    "Write a function named **`sort_by_unique_chars`** that sorts a list of strings based on the number of **unique characters** in each string (**descending** order).  \n",
    "If two strings have the same number of unique characters, sort them **alphabetically**.\n",
    "\n",
    "Assume that the characters in the words are only consisting of lower-case english alphabets\n",
    "\n",
    "### Function Definition (DO NOT CHANGE THIS NAME)\n",
    "\n",
    "```python\n",
    "def sort_by_unique_chars(words):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "raN8xd6gpZRY"
   },
   "source": [
    "check your code by running the below block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "aborted",
     "timestamp": 1765211457701,
     "user": {
      "displayName": "Ayush Chaudhary",
      "userId": "00125398721957339855"
     },
     "user_tz": -330
    },
    "id": "WZZZQS8PpV0D"
   },
   "outputs": [],
   "source": [
    "#example case\n",
    "input_data = [\"apple\", \"banana\", \"kiwi\", \"grape\", \"mango\"]\n",
    "output = sort_by_unique_chars(input_data)\n",
    "print(output)\n",
    "# Expected Output:\n",
    "# ['grape', 'mango', 'apple', 'banana', 'kiwi']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mLdlWr-JsRAl"
   },
   "source": [
    "# **Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "aborted",
     "timestamp": 1765211457702,
     "user": {
      "displayName": "Ayush Chaudhary",
      "userId": "00125398721957339855"
     },
     "user_tz": -330
    },
    "id": "p5XvCADdsKP3"
   },
   "outputs": [],
   "source": [
    "def sort_by_unique_chars(words):\n",
    "  def sort_key(word):\n",
    "      unique_count = len(set(word))\n",
    "      return (-unique_count, word)\n",
    "\n",
    "  return sorted(words, key=sort_key)\n",
    "\n",
    "\n",
    "input_data = [\"apple\",\"banana\",\"kiwi\",\"mango\",\"grapes\"]\n",
    "output = sort_by_unique_chars(input_data)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jZ6s8-zU87b3"
   },
   "source": [
    "# **Section 2 (NumPy)**\n",
    "# **Problem 1**\n",
    "\n",
    "In this problem, you will work with NumPy arrays to practice masking, slicing, advanced indexing, and broadcasting. Follow each step sequentially using only NumPy operations (no Python loops).\n",
    "\n",
    "## **Problem Statement**\n",
    "\n",
    "1. **Generate** a 10×10 NumPy array `X` containing random integers between **0 and 100** (inclusive).\n",
    "\n",
    "2. Create a **boolean mask** selecting all values between **20 and 50** (inclusive).   \n",
    "   Using this mask, replace those values in `X` with **−1** *in-place*.\n",
    "\n",
    "3. Extract a **6×6 submatrix** `sub` from the modified `X`:\n",
    "   - Rows **2 to 8** ( 8 excluded )\n",
    "   - Columns **3 to 9** ( 9 excluded )\n",
    "\n",
    "4. Using **advanced NumPy indexing**, extract all **diagonal elements** of the 6×6 submatrix `sub` into a 1D array `diag_vals`.  \n",
    "   *Hint: use* `np.arange(6)`.\n",
    "\n",
    "5. Construct a **10×10 structured matrix** `M` using broadcasting, where:\n",
    "\n",
    "    `M[i, j] = (i - j)²`\n",
    "\n",
    "    for all `0 ≤ i, j < 10`. This must be done **without loops**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "31dw_CsVzoSh"
   },
   "source": [
    "# **Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "aborted",
     "timestamp": 1765211457702,
     "user": {
      "displayName": "Ayush Chaudhary",
      "userId": "00125398721957339855"
     },
     "user_tz": -330
    },
    "id": "eYUP-eO8zt9Q"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.random.randint(0, 101, (10, 10))\n",
    "mask = (X >= 20) & (X <= 50)\n",
    "X[mask] = -1\n",
    "\n",
    "sub = X[2:8, 3:9]\n",
    "idx = np.arange(6)\n",
    "diag_vals = sub[idx, idx]\n",
    "\n",
    "i = np.arange(10).reshape(-1, 1)\n",
    "j = np.arange(10).reshape(1, -1)\n",
    "M = (i - j) ** 2\n",
    "\n",
    "print(X)\n",
    "print(\"\\n\", sub)\n",
    "print(\"\\n\", diag_vals)\n",
    "print(\"\\n\", M)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aPBuM6-aBcaV"
   },
   "source": [
    "# **Problem 2**\n",
    "\n",
    "In this problem, you will work with NumPy arrays representing class scores for multiple samples.\n",
    "You will practice row-wise normalization, broadcasting, and boolean masking.\n",
    "\n",
    "## **Problem Statement**\n",
    "\n",
    "1. Create a NumPy array `scores` of shape 5×4 containing integer values between **0 and 20** (inclusive).  \n",
    "   Each row represents a sample, and each column represents a score for one of the 4 classes.\n",
    "\n",
    "2. For each row in `scores`, subtract the **maximum value of that row** from all elements in that row.  \n",
    "   This operation must be performed using **broadcasting** (no loops allowed).\n",
    "\n",
    "   *Hint:*  \n",
    "   `scores.max(axis=1, keepdims=True)` produces a (5×1) column of row-wise maxima.\n",
    "\n",
    "3. Compute a new array `exp_scores` by applying the exponential function to each element:\n",
    "\n",
    "   `exp_scores = np.exp(shifted_scores)`\n",
    "\n",
    "4. **Normalize each row** of `exp_scores` so that each row sums to **1**.  \n",
    "   Store the resulting array in `probs`.  \n",
    "\n",
    "   The transformation is conceptually shown by the formula:\n",
    "\n",
    "   <img src=\"https://miro.medium.com/v2/resize:fit:300/1*bol3L-WNVacCscvG-rlypQ.png\" width=\"250\"/>\n",
    "\n",
    "   Which corresponds to:\n",
    "\n",
    "   `probs[i, j] = exp_scores[i, j]/sum(exp_scores[i, :])`\n",
    "\n",
    "5. Compute the **predicted class** for each sample by taking the index of the largest value in each row of `probs`.  \n",
    "   Store this in a 1D array `y_pred` of length 5.\n",
    "\n",
    "6. Create a NumPy array `y_true` of length 5 containing the true class labels (each between 0 and 3).\n",
    "\n",
    "7. Create a boolean array `correct_mask` indicating whether each predicted label matches the true label.  \n",
    "   Then compute the **accuracy** using:\n",
    "\n",
    "   `accuracy = correct_mask.mean()`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D3U8u7XZAhJG"
   },
   "source": [
    "# **Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "aborted",
     "timestamp": 1765211457702,
     "user": {
      "displayName": "Ayush Chaudhary",
      "userId": "00125398721957339855"
     },
     "user_tz": -330
    },
    "id": "VFu9n0GzAkWj"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "scores = np.random.randint(0, 21, size=(5, 4))\n",
    "print(\"Scores:\\n\", scores)\n",
    "\n",
    "shifted_scores = scores - scores.max(axis=1, keepdims=True)\n",
    "print(\"\\nShifted Scores:\\n\", shifted_scores)\n",
    "\n",
    "exp_scores = np.exp(shifted_scores)\n",
    "print(\"\\nExp Scores:\\n\", exp_scores)\n",
    "\n",
    "probs = exp_scores / exp_scores.sum(axis=1, keepdims=True)\n",
    "print(\"\\nProbabilities (Softmax):\\n\", probs)\n",
    "\n",
    "y_pred = probs.argmax(axis=1)\n",
    "print(\"\\nPredicted Classes:\", y_pred)\n",
    "\n",
    "y_true = np.random.randint(0, 4, size=5)\n",
    "print(\"True Labels:\", y_true)\n",
    "\n",
    "correct_mask = (y_pred == y_true)\n",
    "print(\"Correct Mask:\", correct_mask)\n",
    "\n",
    "accuracy = correct_mask.mean()\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7kYf5k_uJPJ_"
   },
   "source": [
    "#Section 3 - Pandas and MatPlotLib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T9xQ3d_AJZai"
   },
   "source": [
    "#Creating Batches for Training and Testing Using Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MdQyxptG28Qc"
   },
   "source": [
    "Download the following .csv file from the given link directly using commands in colab - url = \"https://raw.githubusercontent.com/rashida048/Datasets/master/StudentsPerformance.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "aborted",
     "timestamp": 1765211457702,
     "user": {
      "displayName": "Ayush Chaudhary",
      "userId": "00125398721957339855"
     },
     "user_tz": -330
    },
    "id": "2AtbEMoE3mbI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "aborted",
     "timestamp": 1765211457702,
     "user": {
      "displayName": "Ayush Chaudhary",
      "userId": "00125398721957339855"
     },
     "user_tz": -330
    },
    "id": "dcDOBfBu27z8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HfsUEK234FZ4"
   },
   "source": [
    "Import the csv file as a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "aborted",
     "timestamp": 1765211457702,
     "user": {
      "displayName": "Ayush Chaudhary",
      "userId": "00125398721957339855"
     },
     "user_tz": -330
    },
    "id": "R71A26xy2PcN"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/rashida048/Datasets/master/StudentsPerformance.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "voEqHSEs4Unz"
   },
   "source": [
    "Write the command to be able to see the first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "aborted",
     "timestamp": 1765211457702,
     "user": {
      "displayName": "Ayush Chaudhary",
      "userId": "00125398721957339855"
     },
     "user_tz": -330
    },
    "id": "lUMYefiN0abv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8jKyQxQs4vwT"
   },
   "source": [
    "Create multiple dataframes with the following columns sorted : gender, race, math, reading and writing scores.\n",
    "\n",
    "(meaning create df1, df2, df3 etc. with the math score sorted in df1, gender wise sorted in df2 etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "aborted",
     "timestamp": 1765211457702,
     "user": {
      "displayName": "Ayush Chaudhary",
      "userId": "00125398721957339855"
     },
     "user_tz": -330
    },
    "id": "1hxAdQVnJyQb"
   },
   "outputs": [],
   "source": [
    "# gender\n",
    "df1 = df.sort_values(by=\"gender\")\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "aborted",
     "timestamp": 1765211457702,
     "user": {
      "displayName": "Ayush Chaudhary",
      "userId": "00125398721957339855"
     },
     "user_tz": -330
    },
    "id": "GKpYa5DgJyDO"
   },
   "outputs": [],
   "source": [
    "# race/ethnicity\n",
    "df2 = df.sort_values(by=\"race/ethnicity\")\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "aborted",
     "timestamp": 1765211457702,
     "user": {
      "displayName": "Ayush Chaudhary",
      "userId": "00125398721957339855"
     },
     "user_tz": -330
    },
    "id": "h5vCcwZ3Jzuw"
   },
   "outputs": [],
   "source": [
    "# math\n",
    "df3 = df.sort_values(by=\"math score\")\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "aborted",
     "timestamp": 1765211457702,
     "user": {
      "displayName": "Ayush Chaudhary",
      "userId": "00125398721957339855"
     },
     "user_tz": -330
    },
    "id": "PDY3q-lDJzmj"
   },
   "outputs": [],
   "source": [
    "# reading\n",
    "df4 = df.sort_values(by=\"reading score\")\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "aborted",
     "timestamp": 1765211457702,
     "user": {
      "displayName": "Ayush Chaudhary",
      "userId": "00125398721957339855"
     },
     "user_tz": -330
    },
    "id": "_HkKEL8FJzht"
   },
   "outputs": [],
   "source": [
    "# writing\n",
    "df5 = df.sort_values(by=\"writing score\")\n",
    "df5.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cJIopkiw6fk9"
   },
   "source": [
    "Create 2 non-overlapping dataframes test_df and train_df such that 20% of the rows are in test_df and the rest in train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "aborted",
     "timestamp": 1765211457702,
     "user": {
      "displayName": "Ayush Chaudhary",
      "userId": "00125398721957339855"
     },
     "user_tz": -330
    },
    "id": "AGlTYWKVKB4s"
   },
   "outputs": [],
   "source": [
    "test_df = df.sample(frac=0.2)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "aborted",
     "timestamp": 1765211457702,
     "user": {
      "displayName": "Ayush Chaudhary",
      "userId": "00125398721957339855"
     },
     "user_tz": -330
    },
    "id": "aqWPR4jrKDXg"
   },
   "outputs": [],
   "source": [
    "train_df = df.drop(test_df.index)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RH-90Mm17GNu"
   },
   "source": [
    "Plot a bar graph such that you can see the distribution of race in test and train dataset. Are the proportions of races almost same in train and test datasets ? If not what can you do so that the proportions of races in the test and train datasets are close ?\n",
    "\n",
    "\n",
    "Hint : Think Sorting on the race/ethnicity column and then applying some logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "aborted",
     "timestamp": 1765211457702,
     "user": {
      "displayName": "Ayush Chaudhary",
      "userId": "00125398721957339855"
     },
     "user_tz": -330
    },
    "id": "Km_3XZ3dKXPh"
   },
   "outputs": [],
   "source": [
    "# to clarify if the split of races A, B, C, D and E are nearly say 0.2, 0.15, 0.25, 0.17, 0.23\n",
    "# then I expect an almost similar split in the train_df and test_df\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test_counts = test_df[\"race/ethnicity\"].value_counts()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "test_counts.plot(kind=\"bar\", color=\"lightgreen\")\n",
    "\n",
    "plt.title(\"Race Distribution in TEST Dataset\")\n",
    "plt.xlabel(\"Race/Ethnicity\")\n",
    "plt.ylabel(\"Count\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "aborted",
     "timestamp": 1765211457703,
     "user": {
      "displayName": "Ayush Chaudhary",
      "userId": "00125398721957339855"
     },
     "user_tz": -330
    },
    "id": "7mC4f0w7KGnW"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_counts = train_df[\"race/ethnicity\"].value_counts()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "train_counts.plot(kind=\"bar\", color=\"skyblue\")\n",
    "\n",
    "plt.title(\"Race Distribution in TRAIN Dataset\")\n",
    "plt.xlabel(\"Race/Ethnicity\")\n",
    "plt.ylabel(\"Count\")\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZMkOgiMyKHb8"
   },
   "source": [
    "Even if it the proportions are almost same think of a way to create the train_df and test_df to have similar proportions of races."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "aborted",
     "timestamp": 1765211457703,
     "user": {
      "displayName": "Ayush Chaudhary",
      "userId": "00125398721957339855"
     },
     "user_tz": -330
    },
    "id": "NaI-_726K3Pv"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# we want 20% test, 80% train (you can change this)\n",
    "test_frac = 0.2\n",
    "\n",
    "train_parts = []\n",
    "test_parts = []\n",
    "\n",
    "# group by race/ethnicity\n",
    "for race, group in df.groupby(\"race/ethnicity\"):\n",
    "    # take 20% rows from THIS race group into test\n",
    "    test_part = group.sample(frac=test_frac, random_state=42)\n",
    "    # remaining rows of this race group go to train\n",
    "    train_part = group.drop(test_part.index)\n",
    "\n",
    "    test_parts.append(test_part)\n",
    "    train_parts.append(train_part)\n",
    "\n",
    "# combine all race-wise parts\n",
    "train_df = pd.concat(train_parts).reset_index(drop=True)\n",
    "test_df  = pd.concat(test_parts).reset_index(drop=True)\n",
    "print(\"Full data:\\n\", df[\"race/ethnicity\"].value_counts(normalize=True))\n",
    "print(\"\\nTrain:\\n\", train_df[\"race/ethnicity\"].value_counts(normalize=True))\n",
    "print(\"\\nTest:\\n\", test_df[\"race/ethnicity\"].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S4l17LM084YD"
   },
   "source": [
    "Usually when we train machine learning models we use batches. Each batch is a subset of train_df of legth batch_size. Create Batches: a list of batch each of size 50 from the train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "aborted",
     "timestamp": 1765211457703,
     "user": {
      "displayName": "Ayush Chaudhary",
      "userId": "00125398721957339855"
     },
     "user_tz": -330
    },
    "id": "t-FpW6kyK3lg"
   },
   "outputs": [],
   "source": [
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "executionInfo": {
     "elapsed": 13,
     "status": "aborted",
     "timestamp": 1765211457703,
     "user": {
      "displayName": "Ayush Chaudhary",
      "userId": "00125398721957339855"
     },
     "user_tz": -330
    },
    "id": "3sypY6GELbqx"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "batch_size = 50\n",
    "\n",
    "batches = [\n",
    "    train_df[i : i + batch_size]\n",
    "    for i in range(0, len(train_df), batch_size)\n",
    "]\n",
    "\n",
    "print(\"Total rows in train_df:\", len(train_df))\n",
    "print(\"Batch size:\", batch_size)\n",
    "print(\"Number of batches:\", len(batches))\n",
    "print(\"\\nFirst batch:\")\n",
    "print(batches[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Clkd3lR1_ON-"
   },
   "source": [
    "Print the size of Batches and first few rows of Batches[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "aborted",
     "timestamp": 1765211457703,
     "user": {
      "displayName": "Ayush Chaudhary",
      "userId": "00125398721957339855"
     },
     "user_tz": -330
    },
    "id": "6uVRIfyVLbR0"
   },
   "outputs": [],
   "source": [
    "print(\"Number of batches:\", len(batches))\n",
    "\n",
    "print(\"\\nSize of each batch:\")\n",
    "for i, batch in enumerate(batches):\n",
    "    print(f\"Batch {i}: {len(batch)} rows\")\n",
    "\n",
    "print(\"\\nFirst few rows of batches[0]:\")\n",
    "print(batches[0].head())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1_OIuxdnO-FT08gkEFe3NflKjRv2oVTOO",
     "timestamp": 1765175068482
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
